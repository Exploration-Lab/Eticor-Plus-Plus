{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama31\" # Enter the model name here\n",
    "n_responses = 3\n",
    "\n",
    "temp_response_path = os.path.abspath(f\"../../response_1/pref_bias/{model}\")\n",
    "temp_response_files = os.listdir(temp_response_path)\n",
    "regions = [response_file.split(\"_\")[-1].split(\".\")[0] for response_file in temp_response_files]\n",
    "\n",
    "groups = [\"dining\",\"business\",\"visits\",\"travel\"]\n",
    "prompt_types = [\"one\"]\n",
    "ans_to_region_map = {\"south america\":'la',\"latin america\":\"la\",\"europe\":\"ne\",'asia':'ea',\"east asia\":\"ea\",'africa':'mea',\"middle east\":\"mea\",\"india\":\"india\"}\n",
    "region_to_answer_map = {}\n",
    "region_to_answer_map['la'] = \"latin america\"\n",
    "region_to_answer_map['ea'] = \"east asia\"\n",
    "region_to_answer_map['mea'] = \"middle east\"\n",
    "region_to_answer_map['india'] = \"india\"\n",
    "region_to_answer_map['ne'] = \"europe\"\n",
    "\n",
    "def create_pbr():\n",
    "    pref_bias_regions = {reg:{g:0 for g in [\"dining\",\"business\",\"visits\",\"travel\"]} for reg in regions}\n",
    "    return pref_bias_regions\n",
    "def create_bfs():\n",
    "    bias_for_score = {reg:{g:0 for g in [\"dining\",\"business\",\"visits\",\"travel\"]} for reg in regions}\n",
    "    return bias_for_score\n",
    "def create_bspw():\n",
    "    bias_score_pair_wise = {reg:{r:0 for r in regions} for reg in regions}\n",
    "    return bias_score_pair_wise\n",
    "\n",
    "options = ['india','middle east',\"latin america\",\"east asia\",\"europe\"]\n",
    "def extract_answer(ans:str,region=None,prompt=None):\n",
    "    \"\"\"\n",
    "    Extract the answer from the response text.\n",
    "    The function will return the answer in lowercase.\n",
    "    If the answer is not found, it will return an empty string.\n",
    "    Args:\n",
    "        ans (str): The response text.\n",
    "        region (str): The region of the response.\n",
    "        prompt (str): The prompt text.\n",
    "    Returns:\n",
    "        str: The extracted answer in lowercase.\n",
    "    \"\"\"\n",
    "    patterns = [r\"<s>\",r\"<\\|end\\|>\",r\"<\\|assistant\\|>\",r\"<\\|user\\|>\"]\n",
    "    gen = \"\"\n",
    "    if prompt:\n",
    "        prompt = re.sub(\"|\".join(patterns), \"\", prompt)\n",
    "        gen = ans[len(prompt):].lower()\n",
    "    else:\n",
    "        gen = ans.lower()\n",
    "    ret = []\n",
    "\n",
    "    for opt in options:\n",
    "        if opt in gen:\n",
    "            ret.append(opt)\n",
    "    if len(ret):\n",
    "        return ret\n",
    "    for i,opt in enumerate(options):\n",
    "        if chr(i+1+ord('0')) in gen:\n",
    "            ret.append(opt)\n",
    "    return ret\n",
    "\n",
    "analysis_pbs_bfs_array = np.zeros((2,5, n_responses))\n",
    "analysis_bspw_array = np.zeros((5,5, n_responses))\n",
    "expected_pbs_array = np.zeros((5))\n",
    "expected_bfs_array = 20*np.ones((5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for response_number in range(n_responses):\n",
    "    response_path = os.path.abspath(f\"../../response_{response_number+1}/pref_bias/{model}\")\n",
    "    response_files = os.listdir(response_path)\n",
    "    regions = [response_file.split(\"_\")[-1].split(\".\")[0] for response_file in response_files]\n",
    "    ord_regions = ['NE','INDIA','EA',\"LA\",\"MEA\"]\n",
    "    ord_regions = [el.lower() for el in ord_regions]\n",
    "\n",
    "    prompt = {typ:{\"pbr\":create_pbr(),\"bfs\":create_bfs(),\"bspw\":create_bspw()} for typ in prompt_types}\n",
    "    total = 0\n",
    "    reg_size = {reg:0 for reg in regions}\n",
    "    print(prompt)\n",
    "\n",
    "    for file in response_files:\n",
    "        df  = pd.read_csv(os.path.join(response_path, file))\n",
    "        region = file.split(\"_\")[-1].split(\".\")[0]\n",
    "        print(region)\n",
    "        for i in range(len(df)):\n",
    "            row = df.iloc[i]\n",
    "            ans_one = extract_answer(str(row['one']))\n",
    "            grp = row['group']\n",
    "            total+=1\n",
    "            reg_size[region] += 1\n",
    "            for ans in ans_one:\n",
    "                prompt['one']['pbr'][ans_to_region_map[ans]][grp] += 1\n",
    "                if region_to_answer_map[region] not in ans_one:\n",
    "                    prompt['one']['bfs'][ans_to_region_map[ans]][grp] += 1\n",
    "                    prompt['one']['bspw'][region][ans_to_region_map[ans]] += 1\n",
    "\n",
    "    sm = sum([reg_size[reg] for reg in ord_regions])\n",
    "    expected_preference_score = {reg:100*reg_size[reg]/sm for reg in ord_regions}\n",
    "\n",
    "    model_preference_score = {reg:np.sum([prompt['one']['pbr'][reg][grp] for grp in groups]) for reg in ord_regions}\n",
    "    model_preference_score = {k:100*v/sum(model_preference_score.values()) for k,v in model_preference_score.items()}\n",
    "\n",
    "    model_score_li = np.array([100*model_preference_score[reg]/sum(model_preference_score.values()) for reg in ord_regions])\n",
    "    expected_pbs_array = np.array([100*expected_preference_score[reg]/sum(expected_preference_score.values()) for reg in ord_regions])\n",
    "\n",
    "\n",
    "    bfs_reg = {reg:0 for reg in regions}\n",
    "    for reg in regions:\n",
    "        for grp in groups:\n",
    "            bfs_reg[reg] += prompt['one']['bfs'][reg][grp]\n",
    "    model_bfs_score = [bfs_reg[reg]/(total-reg_size[reg]) for reg in regions]\n",
    "    model_bfs_li =     np.array([100*x/sum(model_bfs_score) for x in model_bfs_score])\n",
    "    \n",
    "    analysis_pbs_bfs_array[0][:][response_number] = model_score_li\n",
    "    analysis_pbs_bfs_array[1][:][response_number] = model_bfs_li\n",
    "\n",
    "    for i,reg in enumerate(regions):\n",
    "        print(f\"Region: {reg}\")\n",
    "        bspw_reg = {reg:0 for reg in regions}\n",
    "        for r in regions:\n",
    "            bspw_reg[r] += prompt['one']['bspw'][reg][r]\n",
    "        analysis_bspw_array[i][:][response_number] = np.array([bspw_reg[r] for r in regions])\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pbs_bfs_array = np.mean(analysis_pbs_bfs_array,axis=2)\n",
    "std_pbs_bfs_array = np.std(analysis_pbs_bfs_array,axis=2)\n",
    "std_pbs = np.sqrt(np.sum((mean_pbs_bfs_array[0]-expected_pbs_array)**2)/5)\n",
    "std_bfs = np.sqrt(np.sum((mean_pbs_bfs_array[1]-expected_bfs_array)**2)/5)\n",
    "\n",
    "mean_bspw_array = np.mean(analysis_bspw_array,axis=2)   \n",
    "std_bspw_array = np.std(analysis_bspw_array,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = [20, 20] \n",
    "# def overall_preference():\n",
    "#     for typ in prompt_types:\n",
    "#         print(f\"Prompt Type: {typ}\")\n",
    "#         pref_reg = {reg:0 for reg in regions}\n",
    "#         for reg in regions:\n",
    "#             for grp in groups:\n",
    "#                 pref_reg[reg] += prompt[typ]['pbr'][reg][grp]\n",
    "#         pi_response_sizes = [pref_reg[reg] for reg in regions]\n",
    "#         print(np.std([100*pref_reg[reg]/sum(pref_reg.values()) for reg in regions]))\n",
    "#         print([100*pref_reg[reg]/sum(pref_reg.values()) for reg in regions])\n",
    "#         pi_response_labels  = [reg for reg in regions]\n",
    "#         plt.pie(pi_response_sizes, labels=pi_response_labels,autopct='%1.1f%%')\n",
    "#         plt.title(f\"Preference Bias for {typ} prompt in model {model}\")\n",
    "#         plt.show()\n",
    "# def group_wise_bias():\n",
    "#     for typ in prompt_types:\n",
    "#         fig, axes = plt.subplots(1, 4, figsize=(20, 5))  # 1 row and 4 columns for the subplots\n",
    "#         fig.suptitle(f\"Pie Charts for {typ} prompt in model {model}\", fontsize=16)\n",
    "#         # print(f\"Prompt Type: {typ}\")\n",
    "#         for i,grp in enumerate(groups):\n",
    "#             print(f\"Group: {grp}\")\n",
    "#             pref_grp = {reg:0 for reg in regions}\n",
    "#             for reg in regions:\n",
    "#                 pref_grp[reg] += prompt[typ]['pbr'][reg][grp]\n",
    "#             pi_response_sizes = [pref_grp[reg] for reg in regions]\n",
    "#             pi_response_labels  = [reg for reg in regions]\n",
    "#             axes[i].pie(pi_response_sizes, labels=pi_response_labels,autopct='%1.1f%%')\n",
    "#             axes[i].set_title(f\"Preference Bias for {typ} prompt for {grp}\")\n",
    "#         plt.show()\n",
    "# def overall_bias_for_score():\n",
    "#     for typ in prompt_types:\n",
    "#         print(f\"Prompt Type: {typ}\")\n",
    "#         pref_reg = {reg:0 for reg in regions}\n",
    "#         for reg in regions:\n",
    "#             for grp in groups:\n",
    "#                 pref_reg[reg] += prompt[typ]['bfs'][reg][grp]\n",
    "#         pi_response_sizes = [pref_reg[reg]/(total-reg_size[reg]) for reg in regions]\n",
    "#         print(np.std([100*x/sum(pi_response_sizes) for x in pi_response_sizes]))\n",
    "#         print([100*x/sum(pi_response_sizes) for x in pi_response_sizes])\n",
    "#         pi_response_labels  = [reg for reg in regions]\n",
    "#         plt.pie(pi_response_sizes, labels=pi_response_labels,autopct='%1.1f%%')\n",
    "#         plt.title(f\"Bias for {typ} prompt in model {model}\")\n",
    "#         plt.show()\n",
    "# def bias_for_score():\n",
    "#     for typ in prompt_types:\n",
    "#         fig, axes = plt.subplots(1, 4, figsize=(20, 5))  # 1 row and 4 columns for the subplots\n",
    "#         fig.suptitle(f\"Pie Charts for {typ} prompt in model {model}\", fontsize=16)\n",
    "#         # print(f\"Prompt Type: {typ}\")\n",
    "#         for i,grp in enumerate(groups):\n",
    "#             print(f\"Group: {grp}\")\n",
    "#             pref_grp = {reg:0 for reg in regions}\n",
    "#             for reg in regions:\n",
    "#                 pref_grp[reg] += prompt[typ]['bfs'][reg][grp]\n",
    "#             pi_response_sizes = [pref_grp[reg] for reg in regions]\n",
    "#             pi_response_labels  = [reg for reg in regions]\n",
    "#             axes[i].pie(pi_response_sizes, labels=pi_response_labels,autopct='%1.1f%%')\n",
    "#             axes[i].set_title(f\"Bias for {typ} prompt for {grp}\")\n",
    "#         plt.show()\n",
    "# def bias_score_pair_wise():\n",
    "#     for typ in prompt_types:\n",
    "#         fig, axes = plt.subplots(1, 5, figsize=(20, 5))  # 1 row and 4 columns for the subplots\n",
    "#         fig.suptitle(f\"Pie Charts for {typ} prompt in model {model}\", fontsize=16)\n",
    "#         # print(f\"Prompt Type: {typ}\")\n",
    "#         for i,reg in enumerate(regions):\n",
    "#             print(f\"Region: {reg}\")\n",
    "#             pref_reg = {reg:0 for reg in regions}\n",
    "#             for r in regions:\n",
    "#                 pref_reg[r] += prompt[typ]['bspw'][reg][r]\n",
    "#             pi_response_sizes = [pref_reg[r] for r in regions]\n",
    "#             pi_response_labels  = [r for r in regions]\n",
    "#             axes[i].pie(pi_response_sizes, labels=pi_response_labels,autopct='%1.1f%%')\n",
    "#             axes[i].set_title(f\"Bias for {typ} prompt for {reg}\")\n",
    "#         plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sidexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
